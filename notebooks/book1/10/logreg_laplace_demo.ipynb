{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Meduri Venkata Shivaditya\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "\n",
    "try:\n",
    "    import bayes_logistic  # pip install -qq bayes_logistic\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq bayes_logistic\n",
    "    import bayes_logistic  # pip install -qq bayes_logistic\n",
    "import warnings\n",
    "\n",
    "try:\n",
    "    import probml_utils as pml\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -qq git+https://github.com/probml/probml-utils.git\n",
    "    import probml_utils as pml\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "np.random.seed(135)\n",
    "# Creating data\n",
    "N = 30\n",
    "D = 2\n",
    "mu1 = np.hstack((np.ones((N, 1)), 5 * np.ones((N, 1))))\n",
    "mu2 = np.hstack((-5 * np.ones((N, 1)), np.ones((N, 1))))\n",
    "class1_std = 1\n",
    "class2_std = 1.1\n",
    "X_1 = np.add(class1_std * np.random.randn(N, 2), mu1)\n",
    "X_2 = np.add(2 * class2_std * np.random.randn(N, 2), mu2)\n",
    "X = np.vstack((X_1, X_2))\n",
    "t = np.vstack((np.ones((N, 1)), np.zeros((N, 1))))\n",
    "\n",
    "# Plotting data\n",
    "x_1, y_1 = X[np.where(t == 1)[0]].T\n",
    "x_2, y_2 = X[np.where(t == 0)[0]].T\n",
    "plt.figure(0)\n",
    "plt.scatter(x_1, y_1, c=\"red\", s=20, marker=\"o\")\n",
    "plt.scatter(x_2, y_2, c=\"blue\", s=20, marker=\"o\")\n",
    "\n",
    "# Plotting Predictions\n",
    "alpha = 100\n",
    "Range = 8\n",
    "step = 0.1\n",
    "xx, yy = np.meshgrid(np.arange(-Range, Range, step), np.arange(-Range, Range, step))\n",
    "[n, n] = xx.shape\n",
    "W = np.hstack((xx.reshape((n * n, 1)), yy.reshape((n * n, 1))))\n",
    "Xgrid = W\n",
    "ws = np.array([[3, 1], [4, 2], [5, 3], [7, 3]])\n",
    "col = [\"black\", \"red\", \"green\", \"blue\"]\n",
    "for ii in range(ws.shape[0]):\n",
    "    w = ws[ii][:]\n",
    "    pred = 1.0 / (1 + np.exp(np.dot(-Xgrid, w)))\n",
    "    plt.contour(xx, yy, pred.reshape((n, n)), 1, colors=col[ii])\n",
    "plt.title(\"data\")\n",
    "pml.savefig(\"logreg_laplace_data.pdf\", dpi=300)\n",
    "\n",
    "\n",
    "# Plot prior, likelihood, posterior\n",
    "\n",
    "Xt = np.transpose(X)\n",
    "f = np.dot(W, Xt)\n",
    "log_prior = np.log(multivariate_normal.pdf(W, cov=(np.identity(D)) * alpha))\n",
    "\n",
    "log_like = np.dot(np.dot(W, Xt), t) - np.sum(np.log(1 + np.exp(f)), 1).reshape((n * n, 1))\n",
    "log_joint = log_like.reshape((n * n, 1)) + log_prior.reshape((n * n, 1))\n",
    "\n",
    "# Plotting log-prior\n",
    "# plt.figure(1)\n",
    "# plt.contour(xx, yy, -1*log_prior.reshape((n,n)), 30)\n",
    "# plt.title(\"Log-Prior\")\n",
    "\n",
    "plt.figure(1)\n",
    "plt.contour(xx, yy, -1 * log_like.reshape((n, n)), 30)\n",
    "plt.title(\"Log-Likelihood\")\n",
    "\n",
    "# Plotting points corresponding to chosen lines\n",
    "for ii in range(0, ws.shape[0]):\n",
    "    w = np.transpose(ws[ii, :])\n",
    "    plt.annotate(str(ii + 1), xy=(w[0], w[1]), color=col[ii])\n",
    "\n",
    "j = np.argmax(log_like)\n",
    "wmle = W[j, :]\n",
    "slope = wmle[1] / wmle[0]\n",
    "# plt.axline([wmle[0], wmle[1]], slope=slope)\n",
    "\n",
    "plt.plot([0, 7.9], [0, 7.9 * slope])\n",
    "plt.grid()\n",
    "pml.savefig(\"logreg_laplace_logLik.pdf\", dpi=300)\n",
    "\n",
    "\n",
    "# Plotting the log posterior(Unnormalised\n",
    "plt.figure(2)\n",
    "plt.contour(xx, yy, -1 * log_joint.reshape((n, n)), 30)\n",
    "plt.title(\"Log-Unnormalised Posterior\")\n",
    "j2 = np.argmax(log_joint)\n",
    "wb = W[j2][:]\n",
    "plt.scatter(wb[0], wb[1], c=\"red\", s=100)\n",
    "plt.grid()\n",
    "pml.savefig(\"logreg_laplace_unnormalised_posterior.pdf\", dpi=300)\n",
    "\n",
    "# Plotting the Laplace approximation to posterior\n",
    "plt.figure(3)\n",
    "# https://bayes-logistic.readthedocs.io/en/latest/usage.html\n",
    "# Visit the website above to access the source code of bayes_logistic library\n",
    "# parameter info : bayes_logistic.fit_bayes_logistic(y, X, wprior, H, weights=None, solver='Newton-CG', bounds=None, maxiter=100)\n",
    "wfit, hfit = bayes_logistic.fit_bayes_logistic(\n",
    "    t.reshape((N * D)),\n",
    "    X,\n",
    "    np.zeros(D),\n",
    "    ((np.identity(D)) * 1 / alpha),\n",
    "    weights=None,\n",
    "    solver=\"Newton-CG\",\n",
    "    bounds=None,\n",
    "    maxiter=100,\n",
    ")\n",
    "co = np.linalg.inv(hfit)\n",
    "# wfit represents the posterior parameters (MAP estimate)\n",
    "# hfit represents the posterior Hessian  (Hessian of negative log posterior evaluated at MAP parameters)\n",
    "log_laplace_posterior = np.log(multivariate_normal.pdf(W, mean=wfit, cov=co))\n",
    "plt.contour(xx, yy, -1 * log_laplace_posterior.reshape((n, n)), 30)\n",
    "plt.scatter(wb[0], wb[1], c=\"red\", s=100)\n",
    "plt.title(\"Laplace Approximation to Posterior\")\n",
    "plt.grid()\n",
    "pml.savefig(\"logreg_laplace_posterior.pdf\", dpi=300)\n",
    "\n",
    "\n",
    "# Plotting the predictive distribution for logistic regression\n",
    "plt.figure(5)\n",
    "pred = 1.0 / (1 + np.exp(np.dot(-Xgrid, wfit)))\n",
    "plt.contour(xx, yy, pred.reshape((n, n)), 30)\n",
    "x_1, y_1 = X[np.where(t == 1)[0]].T\n",
    "x_2, y_2 = X[np.where(t == 0)[0]].T\n",
    "plt.scatter(x_1, y_1, c=\"red\", s=20, marker=\"o\")\n",
    "plt.scatter(x_2, y_2, c=\"blue\", s=40, marker=\"o\")\n",
    "plt.title(\"p(y=1|x, wMAP)\")\n",
    "pml.savefig(\"logreg_laplace_prediction_plugin.pdf\", dpi=300)\n",
    "\n",
    "# Decision boundary for sampled w\n",
    "plt.figure(6)\n",
    "plt.scatter(x_1, y_1, c=\"red\", s=20, marker=\"o\")\n",
    "plt.scatter(x_2, y_2, c=\"blue\", s=20, marker=\"o\")\n",
    "predm = np.zeros((n * n, 1))\n",
    "s = 100\n",
    "for i in range(s):\n",
    "    wsamp = np.random.multivariate_normal(mean=wfit, cov=co)\n",
    "    pred = 1.0 / (1 + np.exp(np.dot(-Xgrid, wsamp)))\n",
    "    predm = np.add(predm, pred.reshape((n * n, 1)))\n",
    "    plt.contour(xx, yy, pred.reshape((n, n)), np.array([0.5]))\n",
    "plt.title(\"Decision boundary for sampled w\")\n",
    "pml.savefig(\"logreg_laplace_prediction_samples.pdf\", dpi=300)\n",
    "\n",
    "# MC\n",
    "plt.figure(7)\n",
    "predm = predm / s\n",
    "plt.contour(xx, yy, predm.reshape((n, n)), 30)\n",
    "plt.scatter(x_1, y_1, c=\"red\", s=20, marker=\"o\")\n",
    "plt.scatter(x_2, y_2, c=\"blue\", s=20, marker=\"o\")\n",
    "plt.title(\"MC approx of p(y=1|x)\")\n",
    "pml.savefig(\"logreg_laplace_prediction_mc.pdf\", dpi=300)\n",
    "\n",
    "# Numerical\n",
    "plt.figure(8)\n",
    "plt.scatter(x_1, y_1, c=\"red\", s=20, marker=\"o\")\n",
    "plt.scatter(x_2, y_2, c=\"blue\", s=20, marker=\"o\")\n",
    "pr = bayes_logistic.bayes_logistic_prob(Xgrid, wfit, hfit)\n",
    "plt.contour(xx, yy, pr.reshape((n, n)), 30)\n",
    "plt.title(\"Deterministic approx of p(y=1|x)\")\n",
    "pml.savefig(\"logreg_laplace_prediction_probit.pdf\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
