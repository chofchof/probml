# 11. Linear Regression

The key property of the linear regression model is that the expected value of the output is assumed to be a linear function of the input, $\mathbb{E}[y|x]=w^Tx$.




## 11.2 Least squares linear regression

$$
p(y|x;\theta) = \mathcal{N}(y|w^Tx+b,\sigma^2) \tag{11.1}
$$
where $\theta=(w,b,\sigma^2)$. We will usually assume that $x=(1,x_1,\dotsc,x_D)$, so we can absorb the offset (of bias) term $b=w_0$ into the weight vector $w$.

We can always apply a nonlinear transformation to the input features, by replacing $x$ with $\phi(x)$ to get
$$
p(y|x;\theta) = \mathcal{N}(y|w^T\phi(x),\sigma^2) \tag{11.3}
$$


